import streamlit as st
import re
from create_search import (
    load_faiss,
    load_bart,
    load_bert,
    summarize_case,
    predict_judgment,
)
from langchain_retriever import LangChainRetrieval  # âœ… LangChain ì—°ê²°

# âœ… Streamlit ì•± ì„¤ì •
st.set_page_config(page_title="ë²•ë¥  AI ì±—ë´‡", layout="wide")
st.image("./data/doggo.jpg", width=300)
st.title("âš–ï¸ ë²•ë¥  AI ì±—ë´‡")
st.markdown("ğŸ’¡ **íŒë¡€ ê²€ìƒ‰, ìš”ì•½ ë° íŒê²° ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤.**")

# âœ… ëª¨ë¸ ë¡œë”© ìƒíƒœ í‘œì‹œ
with st.spinner("ğŸ”„ ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”..."):

    @st.cache_resource
    def load_models():
        db = load_faiss()
        summarizer_tokenizer, summarizer_model = load_bart()
        judgment_tokenizer, judgment_model = load_bert()
        langchain_retriever = LangChainRetrieval()

        if db is None:
            st.error("âŒ FAISS ë²¡í„° DB ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        return (
            db,
            summarizer_tokenizer,
            summarizer_model,
            judgment_tokenizer,
            judgment_model,
            langchain_retriever,
        )

    # âœ… ëª¨ë¸ ë¡œë”© ì‹¤í–‰
    (
        db,
        summarizer_tokenizer,
        summarizer_model,
        judgment_tokenizer,
        judgment_model,
        langchain_retriever,
    ) = load_models()

st.success("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")


# âœ… ì˜ì–´ ì…ë ¥ ì°¨ë‹¨ í•¨ìˆ˜
# def contains_english(user_input):
#     """ì…ë ¥ê°’ì— ì˜ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
#     return bool(re.search(r"[A-Za-z]", user_input))


# âœ… ì‚¬ìš©ì ì…ë ¥
user_query = st.text_input(
    "ğŸ“ **ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:**",
    placeholder="ì˜ˆ: ìƒì†ê¶Œì€ ì–´ë–»ê²Œ ê²°ì •ë˜ë‚˜ìš”?",
    key="user_input",
)

# âœ… ê²€ìƒ‰ ë²„íŠ¼
if st.button("ğŸ” ê²€ìƒ‰ ì‹¤í–‰"):
    if not user_query.strip():
        st.warning("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”!")

    # elif contains_english(user_query):  # âœ… ì˜ì–´ ì…ë ¥ ì°¨ë‹¨
    #     st.warning("âŒ ì˜ì–´ ì…ë ¥ì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•œê¸€ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    else:
        with st.spinner("ğŸ” ê²€ìƒ‰ ì¤‘..."):
            result_text = ""

            # âœ… 1. FAISS ê²€ìƒ‰
            search_result = "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
            if db:
                try:
                    search_results = db.similarity_search(user_query, k=3)
                    search_result = "\n".join(
                        [doc.page_content for doc in search_results]
                    )
                    result_text += f"âœ… **ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼:**\n{search_result}\n"
                except Exception as e:
                    result_text += f"âŒ **ê²€ìƒ‰ ì˜¤ë¥˜:** {str(e)}\n"

            # âœ… 2. BART íŒë¡€ ìš”ì•½
            summary = "âŒ íŒë¡€ ìš”ì•½ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"
            if summarizer_model:
                summary = summarize_case(
                    search_result, summarizer_tokenizer, summarizer_model
                )
                result_text += f"\nâœ… **íŒë¡€ ìš”ì•½:**\n{summary}\n"

            # âœ… 3. BERT íŒê²° ì˜ˆì¸¡
            prediction = "âŒ íŒê²° ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"
            if judgment_model:
                prediction = predict_judgment(
                    search_result, judgment_tokenizer, judgment_model
                )
                result_text += f"\nâœ… **íŒê²° ì˜ˆì¸¡ ê²°ê³¼:** {prediction}\n"

            # âœ… 4. LLM ìµœì¢… ë‹µë³€ ìƒì„±
            final_answer = "âŒ LLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨"
            if langchain_retriever:
                try:
                    final_answer = langchain_retriever.generate_legal_answer(
                        user_query, summary
                    )
                except Exception as e:
                    final_answer = f"âŒ LLM ì˜¤ë¥˜: {str(e)}"

            # âœ… ê²°ê³¼ ì¶œë ¥ (ì¹´ë“œ í˜•ì‹)
            st.markdown("---")
            st.subheader("ğŸ“Œ ê²€ìƒ‰ ê²°ê³¼")
            st.text_area("ğŸ” ê²€ìƒ‰ ê²°ê³¼", value=search_result, height=150, disabled=True)

            st.subheader("ğŸ“Œ íŒë¡€ ìš”ì•½")
            st.text_area("ğŸ“– ìš”ì•½ ê²°ê³¼", value=summary, height=120, disabled=True)

            st.subheader("ğŸ“Œ LLM ìµœì¢… ë‹µë³€")
            st.text_area("ğŸ¤– AI ë‹µë³€", value=final_answer, height=150, disabled=True)

            st.success("âœ… ê²€ìƒ‰ ì™„ë£Œ!")
            st.write("ğŸ“Œ [DEBUG] FAISS ê²€ìƒ‰ í™œì„±í™” ì—¬ë¶€:", bool(db))
            st.write("ğŸ“Œ [DEBUG] LLM í™œì„±í™” ì—¬ë¶€:", bool(langchain_retriever))
