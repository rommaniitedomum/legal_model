model.shared.weight 모델 ([30000, 7698]) 


1️입력 문장 토큰화
2️입력을 임베딩 벡터로 변환
3️인코더를 통과하며 Self-Attention 및 FFN 적용
4️인코더 출력을 바탕으로 디코더가 Self-Attention 및 Cross-Attention 수행
5디코더 출력을 어휘(30,000개) 확률 분포로 변환하여 최종 출력 생성


bart 모델 = 시퀸스 투 시퀸스에 마스킹을 적용해서 노이즈를 만든 모델 